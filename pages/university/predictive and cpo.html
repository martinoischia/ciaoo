

<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>Predictive distribution and CPO in bayesian statistics</title>
    <meta name="description" content="Pagina per tenere traccia del mio ipertesto mentale">
    <meta name="author" content="Martino Ischia">

    <!-- Enable responsive viewport -->
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <!-- Le styles -->
    <link href="/assets/themes/twitter/bootstrap/css/bootstrap.2.2.2.min.css" rel="stylesheet">
    <link href="/assets/themes/twitter/css/style.css?body=1" rel="stylesheet" type="text/css" media="all">
    <link href="/assets/themes/twitter/css/kbroman.css" rel="stylesheet" type="text/css" media="all">

    <!-- Le fav and touch icons -->

    <!-- atom & rss feed -->
    <link href="nil" type="application/atom+xml" rel="alternate" title="Sitewide ATOM Feed">
    <link href="nil" type="application/rss+xml" rel="alternate" title="Sitewide RSS Feed">

  </head>

  <body>
    <div class="navbar">
      <div class="navbar-inner">
        <div class="container-narrow">
          <a class="brand" href="/">pagina personale di Martino</a>
        </div>
      </div>
    </div>

    <div class="container-narrow">

      <div class="content">
        

<div class="page-header">
  <h2>Predictive distribution and CPO in bayesian statistics </h2>
</div>

<div class="row-fluid">
  <div class="span12">
    <p>Predictive distributions and Conditional Predictive Ordinates (CPO) appear in statistics for different 
reasons, the first to make predictions on future observations, the latter for checking the 
goodness of fit of a model or rather for selecting a model among many. But they share the same mathematics, and that’s
why they are put together in this article. <br />
In the following, we are working in a bayesian setting, that is the setting in which not only the observed data
are assumed to be randomly distributed according to a certain law that depends on some
unknown parameters, but also the parameters themselves
are randomly distributed according to a prior distribution. In this setting, statisticians “play” around 
the joint distribution of the data and the parameters. Let’s see a little bit how.</p>

<h5 id="notation">Notation</h5>
<ul>
  <li>$\pi(\boldsymbol{\theta})$ prior distribution for the unknown
 vector of parameters $\boldsymbol{\theta}$</li>
  <li>$\mathbf{Y}$ vector of observed data</li>
  <li>$\mathcal{L}(\mathbf{Y}|\boldsymbol{\theta})$ law of the data $\mathbf{Y}$
given the parameters $\boldsymbol{\theta}$</li>
  <li>$m(\mathbf{Y})$ the marginal law of
$\mathbf{Y}$, that is the law of the data when the parameters of the model get integrated out
<script type="math/tex">m(\mathbf{Y})=\int_\boldsymbol\Theta{\mathcal{L}(\boldsymbol{Y}|\boldsymbol{\theta})\pi(\boldsymbol\theta)d\boldsymbol\theta}</script></li>
</ul>

<h4 id="bayes-theorem">Bayes theorem</h4>
<p>Similarly to the Bayes formula for discrete probabilities that is taught in every course in probability, it is
possible to prove that the following formula holds</p>

<script type="math/tex; mode=display">\pi(\boldsymbol{\theta}|\mathbf{Y})= \frac{\mathcal{L}(\mathbf{Y}|\boldsymbol{\theta})\cdot\pi(\boldsymbol{\theta})}
{m(\mathbf{Y})}</script>

<p>$\pi(\boldsymbol{\theta}|\mathbf{Y})$ is called the posterior distribution of $\boldsymbol\theta$.</p>

<h4 id="predictions">Predictions</h4>
<p>Suppose that we have observed $n$ data $Y_1 … Y_n$, collected in the vector $\mathbf{Y}$, and
that we are interested in deriving the distribution of a new observation
$Y_{new}$. Once we have found the distribution, it will be easy to make predictions: for example,
we can use the mean of the distribution as our guess for the value of $Y_{new}$, or choose another
criterion we think is the most suitable for the problem.<br />
Using the definition of conditional probability</p>

<script type="math/tex; mode=display">\mathcal{L}(Y_{new}|\mathbf{Y})=\frac{m(Y_{new},\mathbf{Y})}{m(\mathbf{Y})}=</script>

<script type="math/tex; mode=display">\frac{\int_\boldsymbol\Theta{\mathcal{L}(Y_{new},\boldsymbol{Y}|\boldsymbol{\theta})\pi(\boldsymbol\theta)d\boldsymbol\theta}}
{m(\mathbf{Y})}</script>

<p>Since the denominator don’t depend depend
on $\boldsymbol\theta$ it can be brought inside the integral.
In the case that the data are conditionally independent, that is</p>

<script type="math/tex; mode=display">\mathcal{L}(\mathbf{Y}|\boldsymbol{\theta})= \prod_{i=1}^n{\mathcal{L}(Y_i|\boldsymbol{\theta})}</script>

<p>the quantity above becomes</p>

<script type="math/tex; mode=display">\int_\boldsymbol\Theta{\frac{\mathcal{L}(Y_{new}|\boldsymbol\theta)\cdot
\mathcal{L}(\boldsymbol{Y}|\boldsymbol{\theta})\pi(\boldsymbol\theta)d\boldsymbol\theta}{m(\mathbf{Y})}}</script>

<p>Applying Bayes theorem we get</p>

<script type="math/tex; mode=display">\mathcal{L}(Y_{new}|\mathbf{Y})=\int_\boldsymbol\Theta{\mathcal{L}(Y_{new}|\boldsymbol\theta)\cdot\pi(\boldsymbol{\theta}|\mathbf{Y})d\boldsymbol{\theta}}</script>

<p>that is the predictive distribution is the integral of the law of $Y_{new}$ given the parameters $\boldsymbol\theta$ with
respect to the posterior distribution of $\boldsymbol\theta$.</p>

<h4 id="conditional-predictive-ordinate">Conditional Predictive Ordinate</h4>


  </div>
</div>


<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>
<script
  type="text/javascript"
  charset="utf-8"
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"
>
</script>
<script
  type="text/javascript"
  charset="utf-8"
  src="https://vincenttam.github.io/javascripts/MathJaxLocal.js"
>
</script>


      </div>
      <hr>
      <footer>
        <p><small>
  <!-- start of Karl's footer; modify this part -->
          <a href="https://creativecommons.org/publicdomain/zero/1.0/"><img src="https://i.creativecommons.org/p/zero/1.0/88x31.png" alt="CC0"/></a> &nbsp;
          <a href="https://kbroman.org/simple_site/">How to make this simple website</a>
  <!-- end of Karl's footer; modify this part -->
        </small></p>
      </footer>

    </div>

    
  </body>
</html>

